## Introduction
Missing data imputation has the potential to have enormous implications on studies and findings. In certain circumstances imputing missing data may be deemed necessary, however, wrongful imputation of missing data, either by type of method or mishandling or misusage by investigators, can lead to biases and/ or inappropriate results. Therefore, it is imperative to have knowledge in the various methodologies of missing data imputation. This study will analyze and assess the impacts of different imputation methodologies, in conjunction with evaluating which method renders the most appropriate outcome. 

## Dataset
The dataset that will be used for this study concerns different chest pain type based on factors such as age, gender, cholesterol levels (mg/dL), and resting blood pressure (mmHg). The chest pain type (cp) is a binary outcome variable that is defined by typical (1) and atypical angina pectoris (0). Age (ï..age) is a continuous, numerical variable which has been restricted to populations > 29 years old. Resting blood pressure (trestbps) and cholesterol (chol) are both continuous, numerical variables that were taken by a trained professional at admission of study. Gender (sex) is a binary variable coded as male and female.

## Methods
The dataset used for this study contains complete number of cases for each variable. Therefore, using R’s MICE package, missing values at an estimated 10% for each variable were imputed through missing at random (MAR). Two continuous variables and two binary variables were selected to have missing values, while one numerical variable, cholesterol, was selected to contain complete number of cases for this study. 

Since the outcome variable, cp, is binary variable, logistic regression modeling was used for prediction.  The methods were conducted using R Markdown V3.5.0.

## Listwise Deletion
Listwise deletion was conducted in by computing the logistic regression equation in R. In R, listwise deletion is the default method in treating missing values. Rows that contain missing values are completely eliminated from the equation.

## Mean/ Mode Imputation
Mean and mode imputation function were used to impute mean values for numerical variables, age and trestbps, and mode imputations were used to assign values for binary variables, cp and sex.

## Random Imputation
Random imputation was conducted by passing through missing variables through a simple random imputation function, which randomly assigned already existing values in lieu of missing values.

## Dummy Variable on Predictors
Dummy variables were generated by implementing a dummy variable function to predict missing values for the following predictors age, trestbps, and sex. Dummy variables assign values by comparing the missing variables to those of complete cases that had missing values replaced by zeros, as a result of the dummy variable function. 

## LVCF
Last value carried forward (LVCF) was not used for this study because this dataset is not applicable. LVCF is used for time series data analyses. 

## Hotdecking (Nearest-Neighbor)
Hotdecking or nearest-neighbor was used through R’s VIM package.  

## Regression Imputation
Through R’s MICE package regression imputation was conducted. Linear regression was conducted using missing numerical variables as the outcome based on prediction by all other variables with complete number of cases. Logistic regression was conducted for missing binary variables as the outcome based on the prediction by all other variables with complete number of cases. The predictions were then used to replace the missing values of the variables and then all variables with imputed values were included to make the final regression model. 

## Regression Imputation with Noise
Using R’s MICE package regression imputation with noise was conducted.  The predicted regression values of numerical variables from the regression imputation method were summed with noise which was estimated through a normal distribution with a mean equal to zero. The missing values of binary variables were assigned values based on the binomial predictions binary values which were rounded to 0 or 1. All imputed variables were included in the final equation to produce the regression imputation with noise model. 

## Multiple Imputation using MI Package
Multiple imputation was performed using R’s MI package. The number of Markov Chains was set to 5 and the number of iterations was set to 100 to allow for better estimation of missing values. Additionally, variables were transformed to increase fit of normality. CP and Sex, both being binary variables, were transformed using binomial estimation. Age and trestbps, both being numerical variables, were transformed using predictive mean matching. Plots were sampled for prior and after multiple imputation was implemented. The final equation was pooled to provide the final estimation.

## Conclusion/ Discussion
By referring to the reuslts, it can be concluded that hot-decking (“nearest-neighbors”) yielded that most accurate estimate to the complete model. While, regression imputation yielded the worst model. This can be a result of the mean of cp being greater than 0.5, therefore through binomial distribution and rounding this can lead to highly elevated numbers of 1 in comparison to 0. Therefore, logistic regression was not able to handle the skewed values of the outcomes. But, surprisingly, regression with noise was able to account for this issue and intensely mitigate the erroneous estimates. 

I hypothesized that multiple imputation would lead to the most accurate measure of the complete model, however, perhaps due to the percent of missing values as well as the distribution of values, hot-decking was able to perform better and yield the best model. To understand whether this is in fact the reason behind these results, further studies using higher or lower proportion of missing values are warranted.
